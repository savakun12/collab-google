{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPu65FJzzHgj2DkehDrwvzA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"fZwc5mfKYh1m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720934498135,"user_tz":-420,"elapsed":2006,"user":{"displayName":"Sava Kun","userId":"07919091345893805591"}},"outputId":"e123a563-03fb-4328-f0a9-615fd15beea4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.32616940581542353\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","          -1       0.30      0.28      0.29       259\n","           0       0.32      0.45      0.37       253\n","           1       0.36      0.26      0.30       279\n","\n","    accuracy                           0.33       791\n","   macro avg       0.33      0.33      0.32       791\n","weighted avg       0.33      0.33      0.32       791\n","\n","Confusion Matrix:\n"," [[ 72 121  66]\n"," [ 76 113  64]\n"," [ 89 117  73]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-23daec0765d5>:50: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['predicted_sentimen'] = y_pred\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# 1. Membaca Data dari File Excel\n","df = pd.read_excel('/content/sample_data/DATA UNTUK NAIVE BAYES.xlsx')\n","\n","# 2. Preprocessing Data\n","def clean_text(text):\n","    text = re.sub(r'http\\S+', '', text)  # menghapus URL\n","    text = re.sub(r'@\\w+', '', text)     # menghapus mention\n","    text = re.sub(r'#\\w+', '', text)     # menghapus hashtag\n","    text = re.sub(r'[^\\w\\s]', '', text)  # menghapus tanda baca\n","    text = text.lower()                  # konversi teks ke huruf kecil\n","    return text\n","\n","# Pastikan semua nilai dalam kolom 'Isi Tweet' adalah string\n","df['Isi Tweet'] = df['Isi Tweet'].astype(str)\n","df['cleaned_tweet'] = df['Isi Tweet'].apply(clean_text)\n","\n","# 3. Mengganti label sentimen manual (Anda dapat menggunakan dataset yang sudah diberi label)\n","# Misalnya, kita membuat kolom 'sentimen' untuk keperluan contoh ini\n","# 1 untuk positif, 0 untuk netral, -1 untuk negatif\n","# Silakan ganti dengan metode pelabelan otomatis atau manual sesuai kebutuhan\n","df['sentimen'] = np.random.choice([1, 0, -1], size=len(df))  # Contoh acak\n","\n","# 4. Ekstraksi Fitur dengan TF-IDF\n","vectorizer = TfidfVectorizer(max_features=5000)\n","X = vectorizer.fit_transform(df['cleaned_tweet']).toarray()\n","y = df['sentimen']\n","\n","# 5. Melatih Model Naive Bayes\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","model = MultinomialNB()\n","model.fit(X_train, y_train)\n","\n","# 6. Menguji Model dan Mengevaluasi Hasil\n","y_pred = model.predict(X_test)\n","\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","\n","# Menyimpan hasil prediksi ke dalam file\n","df_test = df.iloc[y_test.index]\n","df_test['predicted_sentimen'] = y_pred\n","df_test.to_excel('predicted_tweets.xlsx', index=False)\n"]}]}